{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJcv4QKMreRg3pmA4wO5L/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melvinsackaria/DeepLearning/blob/main/WordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s3f_j5f3bgsS"
      },
      "outputs": [],
      "source": [
        "##tensorflow >2.0\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "metadata": {
        "id": "-09XyF5ZbzvE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu2n7gGXb2Pn",
        "outputId": "1e54fd3f-9ea1-4fff-901b-9f2f54b7ce54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the glass of milk',\n",
              " 'the glass of juice',\n",
              " 'the cup of tea',\n",
              " 'I am a good boy',\n",
              " 'I am a good developer',\n",
              " 'understand the meaning of words',\n",
              " 'your videos are good']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Vocabulary size - size of dictionary\n",
        "voc_size=10000"
      ],
      "metadata": {
        "id": "LJnSOmNIdB8C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Representation**\n"
      ],
      "metadata": {
        "id": "9XToGbJ5dEPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
        "print(onehot_repr)#We will be getting index of words from the dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te849qVmdIf-",
        "outputId": "caece0ba-d176-4f72-bbff-3911afa8b3d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4232, 7611, 9798, 7605], [4232, 7611, 9798, 8306], [4232, 289, 9798, 8074], [1335, 8967, 8926, 6459, 8145], [1335, 8967, 8926, 6459, 9616], [6088, 4232, 7072, 9798, 9996], [3640, 5834, 9560, 6459]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Embedding Represntation**\n",
        "\n",
        "Changing to embedding matrix, importanat parameter is the dimensions\n"
      ],
      "metadata": {
        "id": "USrBNGVKdK5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # padding to have all sentences same number of words before sending to embedding layer\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "f6JwUzqpdMAK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GatpBW-4f-qC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length=8 # maximum sentance length i want, padding on top of that\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length) # one hot resp as input, pre - before the word\n",
        "print(embedded_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtPwlGpOgD8m",
        "outputId": "fb367cc9-f86c-4570-ace6-be6bc3ca3daf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 4232 7611 9798 7605]\n",
            " [   0    0    0    0 4232 7611 9798 8306]\n",
            " [   0    0    0    0 4232  289 9798 8074]\n",
            " [   0    0    0 1335 8967 8926 6459 8145]\n",
            " [   0    0    0 1335 8967 8926 6459 9616]\n",
            " [   0    0    0 6088 4232 7072 9798 9996]\n",
            " [   0    0    0    0 3640 5834 9560 6459]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim=10"
      ],
      "metadata": {
        "id": "stleq-SAg2eJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
        "model.compile('adam','mse')"
      ],
      "metadata": {
        "id": "YVmQhmDFg3kI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEW_2rv6hDfW",
        "outputId": "57644121-e655-4e1e-9216-f8c984859a6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 8, 10)             100000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(model.predict(embedded_docs))"
      ],
      "metadata": {
        "id": "SFQPEhvWhErS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjkM-ECchIeO",
        "outputId": "3f23db5b-ac17-49bd-a958-adef07f53307"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 4232, 7611, 9798, 7605], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(embedded_docs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAanVPZXhQkS",
        "outputId": "58dd23cb-f2c1-4260-b6f9-d04e0150fa80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.01802969  0.03989239 -0.02373035  0.04699631 -0.00284908 -0.0160761\n",
            "  -0.04844203 -0.04134765  0.04460403 -0.00746163]\n",
            " [-0.01802969  0.03989239 -0.02373035  0.04699631 -0.00284908 -0.0160761\n",
            "  -0.04844203 -0.04134765  0.04460403 -0.00746163]\n",
            " [-0.01802969  0.03989239 -0.02373035  0.04699631 -0.00284908 -0.0160761\n",
            "  -0.04844203 -0.04134765  0.04460403 -0.00746163]\n",
            " [-0.01802969  0.03989239 -0.02373035  0.04699631 -0.00284908 -0.0160761\n",
            "  -0.04844203 -0.04134765  0.04460403 -0.00746163]\n",
            " [ 0.04941711  0.00588239  0.00263337 -0.03533729  0.01008414  0.04056365\n",
            "   0.02721019  0.02660996  0.01571821 -0.03454082]\n",
            " [-0.0457071  -0.02795789 -0.04754693  0.02753275  0.00427162 -0.01414029\n",
            "  -0.03358044  0.03344137 -0.03008206 -0.02891111]\n",
            " [ 0.00328799 -0.03098323  0.03369984  0.03305835 -0.00208652  0.03132438\n",
            "   0.03331438  0.03541584 -0.0332818   0.04799228]\n",
            " [ 0.04659632  0.02723899 -0.0220552  -0.00670103  0.02085446  0.01150701\n",
            "  -0.00225363  0.03400402 -0.0407638  -0.02487596]]\n"
          ]
        }
      ]
    }
  ]
}